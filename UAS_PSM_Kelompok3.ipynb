{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zUaiw43fC4WX",
        "5ge4j07hC7IC"
      ],
      "authorship_tag": "ABX9TyMr9Jp7vQR/xCj5rFL/j6cL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaanca/UAS_PSM_Kelompok3/blob/main/UAS_PSM_Kelompok3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "zUaiw43fC4WX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22iTkJChCnIY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import librosa\n",
        "import optuna\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "# feature engineering + selection\n",
        "from glob import glob\n",
        "from librosa import feature\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# modelling + evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_audio_files = glob('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/*.wav')\n",
        "\n",
        "all_audio = {}\n",
        "\n",
        "for audio_file in base_audio_files:\n",
        "    # extract filename from path\n",
        "    filename = audio_file.split('\\\\')[-1] # for Windows paths\n",
        "\n",
        "    # load audio file\n",
        "    y, sr = librosa.load(audio_file, mono=True)\n",
        "\n",
        "    # store in dictionary\n",
        "    all_audio[filename] = {\n",
        "        'data': y,\n",
        "        'sample_rate': sr\n",
        "    }\n",
        "\n",
        "print(f'Loaded {len(all_audio)} audio files')"
      ],
      "metadata": {
        "id": "lb3MWBT8Cwi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(all_audio.keys())[:5]"
      ],
      "metadata": {
        "id": "VfjSmW7XC0gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "5ge4j07hC7IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate duration for each audio file\n",
        "for filename, audio_info in all_audio.items():\n",
        "    duration = len(audio_info['data']) / audio_info['sample_rate']\n",
        "    all_audio[filename]['duration'] = duration\n",
        "\n",
        "# find the file with the minimum duration\n",
        "min_duration_file = min(all_audio.items(), key=lambda x: x[1]['duration'])\n",
        "min_filename = min_duration_file[0]\n",
        "min_audio_info = min_duration_file[1]\n",
        "\n",
        "print(f\"Shortest audio file: {min_filename}\")\n",
        "print(f\"Duration: {min_audio_info['duration']:.2f} seconds\")\n",
        "\n",
        "# plot the waveform of the shortest audio file\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(min_audio_info['data'], sr=min_audio_info['sample_rate'])\n",
        "plt.title(f\"Waveform of shortest audio file: {min_filename}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "display.Audio(data=min_audio_info['data'], rate=min_audio_info['sample_rate'])"
      ],
      "metadata": {
        "id": "G5Et580FC91_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_duration = min_audio_info['duration']\n",
        "print(f\"Duration of the shortest audio file: {target_duration} seconds\")\n",
        "\n",
        "trimmed_audio = {}\n",
        "\n",
        "for filename, audio_info in all_audio.items():\n",
        "    target_samples = int(target_duration * audio_info['sample_rate']) # calculate target samples\n",
        "    trimmed_data = audio_info['data'][:target_samples] # trimmed to target duration\n",
        "\n",
        "    # store in dictionary\n",
        "    trimmed_audio[filename] = {\n",
        "        'data': trimmed_data,\n",
        "        'sample_rate': audio_info['sample_rate'],\n",
        "        'duration': target_duration\n",
        "    }\n",
        "\n",
        "print(f'Trimmed all {len(trimmed_audio)} audio files to {target_duration} seconds')"
      ],
      "metadata": {
        "id": "zglPdiCwDE2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the waveform of a sample trimmed audio file\n",
        "sample_file = list(trimmed_audio.keys())[90]\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(trimmed_audio[sample_file]['data'], sr=trimmed_audio[sample_file]['sample_rate'])\n",
        "plt.title(f\"Waveform of trimmed audio file: {sample_file}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zNAnensqDFl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "hNgBiDKLDJPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn_list = [\n",
        "    feature.chroma_stft,       # Chromagram from STFT\n",
        "    feature.mfcc,              # Mel-frequency cepstral coefficients\n",
        "    feature.melspectrogram,    # Mel-scaled spectrogram\n",
        "    feature.spectral_contrast, # Spectral contrast\n",
        "    feature.tonnetz,           # Tonal centroid features\n",
        "    feature.rms,               # Root-mean-square energy\n",
        "    feature.zero_crossing_rate,# Zero crossing rate\n",
        "    feature.spectral_bandwidth,# Spectral bandwidth\n",
        "    feature.spectral_centroid, # Spectral centroid\n",
        "    feature.spectral_flatness, # Spectral flatness\n",
        "    feature.spectral_rolloff,  # Spectral roll-off\n",
        "    feature.poly_features,     # Polynomial features\n",
        "    feature.tempogram          # Tempogram\n",
        "]\n",
        "\n",
        "audio_features = {}\n",
        "\n",
        "# extract features for each audio file\n",
        "for filename, audio_info in trimmed_audio.items():\n",
        "    y = audio_info['data']\n",
        "    sr = audio_info['sample_rate']\n",
        "\n",
        "    audio_features[filename] = {}\n",
        "\n",
        "    audio_features[filename]['chroma_stft'] = feature.chroma_stft(y=y, sr=sr)\n",
        "    audio_features[filename]['mfcc'] = feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    audio_features[filename]['mel_spectrogram'] = feature.melspectrogram(y=y, sr=sr)\n",
        "    audio_features[filename]['spectral_contrast'] = feature.spectral_contrast(y=y, sr=sr)\n",
        "    audio_features[filename]['spectral_centroid'] = feature.spectral_centroid(y=y, sr=sr)\n",
        "    audio_features[filename]['spectral_bandwidth'] = feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    audio_features[filename]['spectral_rolloff'] = feature.spectral_rolloff(y=y, sr=sr)\n",
        "    audio_features[filename]['zero_crossing_rate'] = feature.zero_crossing_rate(y=y)"
      ],
      "metadata": {
        "id": "8yCC04z3DM62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display feature shape for first file\n",
        "sample_file = list(audio_features.keys())[0]\n",
        "for feature_name, feature_data in audio_features[sample_file].items():\n",
        "    print(f\"{feature_name}: {feature_data.shape}\")"
      ],
      "metadata": {
        "id": "No2ZY_Q8DR8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample file to visualize\n",
        "sample_file = list(audio_features.keys())[0]\n",
        "sample_data = trimmed_audio[sample_file]['data']\n",
        "sample_sr = trimmed_audio[sample_file]['sample_rate']\n",
        "\n",
        "# plot mel spectrogram\n",
        "plt.figure(figsize=(12, 4))\n",
        "S = librosa.feature.melspectrogram(y=sample_data, sr=sample_sr, n_mels=128)\n",
        "S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sample_sr)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title(f'Mel-frequency spectrogram: {sample_file}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# plot mfccs\n",
        "plt.figure(figsize=(12, 4))\n",
        "mfccs = librosa.feature.mfcc(y=sample_data, sr=sample_sr, n_mfcc=13)\n",
        "librosa.display.specshow(mfccs, x_axis='time', sr=sample_sr)\n",
        "plt.colorbar()\n",
        "plt.title(f'MFCC: {sample_file}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yhqk6a0XDT7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_stats = []\n",
        "\n",
        "for filename, features in audio_features.items():\n",
        "    file_stats = {'filename': filename}\n",
        "\n",
        "    # calculate statistics for each feature\n",
        "    for feature_name, feature_data in features.items():\n",
        "        file_stats[f'{feature_name}_mean'] = np.mean(feature_data)\n",
        "        file_stats[f'{feature_name}_std'] = np.std(feature_data)\n",
        "        file_stats[f'{feature_name}_max'] = np.max(feature_data)\n",
        "        file_stats[f'{feature_name}_min'] = np.min(feature_data)\n",
        "\n",
        "    feature_stats.append(file_stats)\n",
        "\n",
        "# create dataframe\n",
        "df = pd.DataFrame(feature_stats)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "693DkaN6DW0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read patient diagnosis data\n",
        "patient_diagnosis = pd.read_csv('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv', header=None)\n",
        "patient_diagnosis.columns = ['patient_id', 'diagnosis']\n",
        "\n",
        "patient_diagnosis.head()"
      ],
      "metadata": {
        "id": "aP_3aGruDZAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['filename'] = df['filename'].str.replace('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/', '', regex=False)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "l_9sDH5LDbA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map the diagnosis to the dataframe based on the patient ID extracted from the filename\n",
        "df['diagnosis'] = df['filename'].apply(\n",
        "\tlambda x: patient_diagnosis.loc[\n",
        "\t\tpatient_diagnosis['patient_id'] == int(x.split('_')[0]), 'diagnosis'\n",
        "\t].values[0] if int(x.split('_')[0]) in patient_diagnosis['patient_id'].values else None\n",
        ")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "nV3QxAFNDdwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LECZePTZDfv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Missing values: {df.isna().sum().sum()}\")\n",
        "print(f\"Duplicated rows: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "PkjdDMOgDh4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "D0mvPs49Dl9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.copy()\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "df_2['diagnosis'] = le.fit_transform(df_2['diagnosis'])\n",
        "\n",
        "print(f\"Target value counts: {df_2['diagnosis'].value_counts()}\")\n",
        "\n",
        "# plot target proportion using bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df_2, x='diagnosis', palette='Set2')\n",
        "plt.title('Diagnosis Distribution')\n",
        "plt.xlabel('Diagnosis')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2qhzRV1RDrCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df_2.drop(['filename'], axis=1)\n",
        "\n",
        "corr_mat = df_2.corr()\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(corr_mat, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ksO8hC0lDsvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}